{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import multiprocessing\n",
    "from keras import backend as K\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score,auc , recall_score, accuracy_score, confusion_matrix\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import csv\n",
    "import torch\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from tqdm import tqdm\n",
    "from model import DNN2\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score\n",
    "from data_tool import label_encode,label_decode,eachAccu\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from dataloader import dataSet,data_prefetcher\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "NUMWORKER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =999\n",
    "fea_dim = 2368 # 512/2048/2368/832\n",
    "fea_type = 'tfidf'\n",
    "X = joblib.load('./fea_sel/{}/{}_train-{}.pkl'.format(fea_type,fea_type.lower(),fea_dim))\n",
    "hashtag = [] \n",
    "\n",
    "label = joblib.load('./fea_sel/label/label8.pkl')\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(label)\n",
    "y = label_encode(label_encoder,label)\n",
    "NUM_WORKER = 4\n",
    "lab_size = 8\n",
    "max_features = 2048\n",
    "MAXEPOCH = 15\n",
    "Test =False\n",
    "\n",
    "layer_sizes = [fea_dim,int(fea_dim/4), int(fea_dim/8),int(fea_dim/32)]\n",
    "BZ= [512]\n",
    "LR = [0.001]\n",
    "DP = [0,0.2]\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_clf, trainLoader, optimizer,device=DEVICE):\n",
    "    print(torch.torch.cuda.current_device())\n",
    "#    num =torch.cuda.current_device()\n",
    "#    print(torch.cuda.get_device_name(num))\n",
    "    \n",
    "    num_iter = len(trainLoader)\n",
    "    prefetcher = data_prefetcher(trainLoader)\n",
    "    model_clf = model_clf.train()\n",
    "    preds = []\n",
    "    gnds = []\n",
    "    losses = []\n",
    "#    for  x_batch, y_batch,ID in tqdm(trainLoader):\n",
    "    for batch_idx in tqdm(range(num_iter)):\n",
    "        x_batch,y_batch,ID = prefetcher.next()\n",
    "        \n",
    "        x_batch = x_batch.to(DEVICE).squeeze(1).float()\n",
    "        y_batch = y_batch.flatten().to(DEVICE)\n",
    "#        print(x_batch.is_cuda)\n",
    "#        print(y_batch.is_cuda) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out_train = model_clf(x_batch)\n",
    "        lossCrossEntropyTrain = loss_CrossEntropy(out_train, y_batch)\n",
    "        losses.append(lossCrossEntropyTrain.item())\n",
    "        preds.extend(np.argmax(out_train.detach().cpu().numpy(), axis=1).tolist())\n",
    "        gnds.extend(list(y_batch.detach().cpu().numpy().astype('int')))\n",
    "\n",
    "        lossCrossEntropyTrain.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#        print('\\ntrain loss:{:.5}'.format(lossCrossEntropyTrain.item()))\n",
    "    losses = np.array(losses).mean()\n",
    "    rint('\\ntest loss:{:.5}'.format(losses))\n",
    "    return model_clf, optimizer, preds, gnds, losses\n",
    "\n",
    "\n",
    "def test(model_clf, testLoader,device=DEVICE):\n",
    "    model_clf = model_clf.eval()\n",
    "    IDs = []\n",
    "    preds = []\n",
    "    gnds = []\n",
    "    losses = []\n",
    "    outList = []\n",
    "    num_iter = len(trainLoader)\n",
    "    prefetcher = data_prefetcher(trainLoader)\n",
    "#    for  x_batch, y_batch,ID in tqdm(testLoader):\n",
    "    for batch_idx in tqdm(range(num_iter)):\n",
    "        x_batch,y_batch,ID = prefetcher.next()\n",
    "        # forward\n",
    "        x_batch = x_batch.to(DEVICE).squeeze(1).float()\n",
    "        y_batch = y_batch.flatten().to(DEVICE)\n",
    "        \n",
    "        out_test = model_clf(x_batch )\n",
    "        lossCrossEntropyTest = loss_CrossEntropy(out_test, y_batch)\n",
    "        losses.append(lossCrossEntropyTest.item())\n",
    "        \n",
    "        predictTest = np.argmax(out_test.detach().cpu().numpy(), axis=1)\n",
    "        out = list(out_test.detach().cpu().numpy())\n",
    "        outList.extend(list(map(lambda x: x[1], out)))\n",
    "        preds.extend(predictTest.tolist())\n",
    "        gnds.extend(list(y_batch.detach().cpu().numpy().astype('int')))\n",
    "    losses = np.array(losses).mean()\n",
    "    print('\\ntest loss:{:.5}'.format(losses))\n",
    "    return model_clf,outList, preds, gnds , losses\n",
    "def writer_csv(logPath, logging):\n",
    "    f = open(logPath,'a')\n",
    "    w = csv.writer(f,lineterminator = '\\r')\n",
    "    w.writerow(logging)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bz in BZ:\n",
    "            for lr1 in LR:\n",
    "                for dropout_p in DP:\n",
    "                    X_idex = np.arange(1455563).reshape(-1,1)\n",
    "                    for train_index, test_index in kf.split(X_idex):\n",
    "                        dataset = dataSet(fea_type,str(fea_dim),train_index,train=True)\n",
    "                        trainLoader = torch.utils.data.DataLoader(dataset,batch_size =bz,shuffle=True,num_workers=NUM_WORKER,pin_memory=True)\n",
    "                        dataset = dataSet(fea_type,str(fea_dim),test_index,train=True)\n",
    "                        testLoader = torch.utils.data.DataLoader(dataset,batch_size =bz,shuffle=True,num_workers=NUM_WORKER,pin_memory=True)\n",
    "                        del dataset\n",
    "                        \n",
    "                        lossTrain, lossTest = [[] for i in range(MAXEPOCH)],[[] for i in range(MAXEPOCH)]\n",
    "                        for epoch in range(MAXEPOCH):\n",
    "    #                        print(epoch)\n",
    "                            predTestAll,gndTestAll,outAll = [],[],[]\n",
    "                            predTrainAll,gndTrainAll = [],[] \n",
    "                            if epoch==0:\n",
    "                            \n",
    "                                model_clf = DNN2(layer_sizes=layer_sizes, output_size=lab_size , drop_p=dropout_p).to(DEVICE)\n",
    "                                loss_CrossEntropy = nn.CrossEntropyLoss()\n",
    "                                optimizer = optim.Adam(model_clf.parameters(), lr=lr1)\n",
    "                                # =============================================================================\n",
    "                                #                    Training & Testing & saving models\n",
    "                                # =============================================================================\n",
    "            #                    print('\\n=== training lr{} dp{}  cvIdx{} epo{}===\\n'.format(lr1,dropout_p,cvIdx,epoch))\n",
    "                                print('\\n=== training lr{} dp{}   epo{}===\\n'.format(lr1,dropout_p,epoch))\n",
    "                                model_clf, optimizer, predTrain, gndTrain, losses = train(model_clf, trainLoader, optimizer)\n",
    "                                lossTrain[epoch].append(losses)\n",
    "                                predTrainAll.extend(predTrain)\n",
    "                                gndTrainAll.extend(gndTrain)   \n",
    "                                \n",
    "                                # Testing   \n",
    "                #                print('\\n=== testing lr{} dp{}  cvIdx{} epo{} ===\\n'.format(lr1,dropout_p,cvIdx,epoch))\n",
    "                                print('\\n=== testing lr{} dp{}  ===\\n'.format(lr1,dropout_p))\n",
    "                                model_clf, outTest,predTest, gndTest, losses = test(model_clf, testLoader)\n",
    "                                lossTest[epoch].append(losses)\n",
    "                                predTestAll.extend(predTest)\n",
    "                                gndTestAll.extend(gndTest)\n",
    "                                outAll.extend(outTest)\n",
    "                                # =============================================================================\n",
    "                                #                       Evaluate\n",
    "                                # =============================================================================\n",
    "                                uarTrain = recall_score(gndTrainAll, predTrainAll, average='macro')\n",
    "                                accuTrain = accuracy_score(gndTrainAll, predTrainAll)\n",
    "                                uarTest = recall_score(gndTestAll, predTestAll, average='macro')\n",
    "            #                    aucTest = 0\n",
    "                                _ = eachAccu(predTestAll, gndTestAll) \n",
    "                                accuTest = accuracy_score(gndTestAll, predTestAll)\n",
    "                                cmTest = confusion_matrix(gndTestAll, predTestAll)\n",
    "                        '''if Test:\n",
    "                            logg = './submission.csv'\n",
    "                            writer_csv(logg, ['id','emotion'])\n",
    "                            for id_,emo in zip(testID,pred):\n",
    "                                if emo == 0: w = 'sadness'\n",
    "                                elif emo == 1: w = 'disgust'\n",
    "                                elif emo == 2: w = 'anticipation'\n",
    "                                elif emo == 3: w = 'joy'\n",
    "                                elif emo == 4: w = 'trust'\n",
    "                                elif emo == 5: w = 'anger'\n",
    "                                elif emo == 6: w = 'fear'\n",
    "                                elif emo == 7: w = 'surprise'\n",
    "                                ww= [id_,w]\n",
    "                                writer_csv(logg, ww)'''\n",
    "                        # =============================================================================\n",
    "                        #                       Plotting\n",
    "                        # =============================================================================\n",
    "                        for i in range(MAXEPOCH):\n",
    "                            lossTrain[i] = np.array(lossTrain[i]).mean(axis = 0)\n",
    "                            lossTest[i] = np.array(lossTest[i]).mean(axis = 0)\n",
    "                            \n",
    "                        lossTrain = np.asarray(lossTrain).T\n",
    "                        lossTest = np.asarray(lossTest).T\n",
    "                        \n",
    "                        plt.figure(figsize=(8,4))\n",
    "                        \n",
    "                        plt.plot(lossTrain,label=\"$Training loss$\",color=\"blue\",linewidth=1)\n",
    "                        plt.plot(lossTest,label=\"$Testing loss$\",color='red',linewidth=2)\n",
    "                        plt.xlabel(\"Epoch\")\n",
    "                        plt.ylabel(\"Loss\")\n",
    "                        plt.xticks(range(len(lossTrain)))\n",
    "                        plt.title(\"Loss Plot\")\n",
    "                        plt.legend()\n",
    "                        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
